# k8s
***

## 基本概念
1. master 节点:负责整个集群控制,管理,有以下关键组件

  * kube-apiserver:k8s所有资源crud的接口,是控制集群的入口
  * kube-controller-manager:k8s里所有资源的自动化控制中心
  * kube-seheduler:负责pod调度的进程
2. node 计算节点,负责工作负载,有以下关键组件

  * kubelet:负责pod创建,启停.与master协作管理集群
  * kube-proxy:实现k8s service的通信和lb
  * docker engine:负责本机容器创建和管理


## 部署篇:kubeadm

准备开始

* 一台兼容的 Linux 主机。Kubernetes 项目为基于 Debian 和 Red Hat 的 Linux 发行版以及一些不提供包管理器的发行版提供通用的指令
* 每台机器 2 GB 或更多的 RAM （如果少于这个数字将会影响你应用的运行内存)
2 CPU 核或更多
* 集群中的所有机器的网络彼此均能相互连接(公网和内网都可以)
* 节点之中不可以有重复的主机名、MAC 地址或 product_uuid。请参见这里了解更多详细信息。
*开启机器上的某些端口。请参见这里 了解更多详细信息。
* 禁用交换分区。为了保证 kubelet 正常工作，你 必须 禁用交换分区。

		Kubernetes 1.8开始要求关闭系统的Swap，如果不关闭，默认配置下kubelet将无法启动，关闭系统的Swap方法如下:
	
		swapoff -a
		修改 /etc/fstab 文件，注释掉 SWAP 的自动挂载，使用free -m确认swap已经关闭。 swappiness参数调整，修改/etc/sysctl.d/k8s.conf添加下面一行：
		
		vm.swappiness=0
		执行sysctl -p /etc/sysctl.d/k8s.conf使修改生效。

 ![所需端口](k8s/0.jpg)

***
### 前置工作

#### 确保每个节点上 MAC 地址和 product_uuid 的唯一性

* 你可以使用命令 ip link 或 ifconfig -a 来获取网络接口的 MAC 地址
* 可以使用 sudo cat /sys/class/dmi/id/product_uuid 命令对 product_uuid 校验


一般来讲，硬件设备会拥有唯一的地址，但是有些虚拟机的地址可能会重复。 Kubernetes 使用这些值来唯一确定集群中的节点。 如果这些值在每个节点上不唯一，可能会导致安装 失败。

#### 检查网络适配器 
如果你有一个以上的网络适配器，同时你的 Kubernetes 组件通过默认路由不可达，我们建议你预先添加 IP 路由规则，这样 Kubernetes 集群就可以通过对应的适配器完成连接。

#### 允许 iptables 检查桥接流量
确保 br_netfilter 模块被加载。这一操作可以通过运行 lsmod | grep br_netfilter 来完成。若要显式加载该模块，可执行 sudo modprobe br_netfilter。

为了让你的 Linux 节点上的 iptables 能够正确地查看桥接流量，你需要确保在你的 sysctl 配置中将 net.bridge.bridge-nf-call-iptables 设置为 1。例如：

	cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
	br_netfilter
	EOF
	
	cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
	net.bridge.bridge-nf-call-ip6tables = 1
	net.bridge.bridge-nf-call-iptables = 1
	EOF
	sudo sysctl --system

#### 安装 runtime
略,见安装docker
修改systemd
vi /etc/docker/daemon.json 
{
  "default-runtime":"nvidia",
  "runtimes": {
    "nvidia": {
      "path": "nvidia-container-runtime",
      "runtimeArgs": []
    }
  },
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2",
  "storage-opts": [
    "overlay2.override_kernel_check=true"
  ]
}

systemctl restart docker

***
### 在线部署kubeadm

#### 安装 kubeadm、kubelet 和 kubectl 
在每台机器上安装以下的软件包：

* kubeadm：用来初始化集群的指令。

* kubelet：在集群中的每个节点上用来启动 Pod 和容器等。

* kubectl：用来与集群通信的命令行工具。

		cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
		[kubernetes]
		name=Kubernetes
		baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearch
		enabled=1
		gpgcheck=1
		repo_gpgcheck=1
		gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
		exclude=kubelet kubeadm kubectl
		EOF
		
		# 将 SELinux 设置为 permissive 模式（相当于将其禁用）
		sudo setenforce 0
		sudo sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config
		
		sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes
		
		sudo systemctl enable --now kubelet

注意!!国内源替换为https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/

centos7用户还需要设置路由：

cat <<EOF >  /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
sysctl --system

#### 配置节点
控制平面节点是运行控制平面组件的机器， 包括 etcd （集群数据库） 和 API Server （命令行工具 kubectl 与之通信）。

	1. kubeadm init 启动一个 Kubernetes 主节点
	2. kubeadm join 启动一个 Kubernetes 工作节点并且将其加入到集群
	3. kubeadm upgrade 更新一个 Kubernetes 集群到新版本
	4. kubeadm config 如果使用 v1.7.x 或者更低版本的 kubeadm 初始化集群，您需要对集群做一些配置以便使用 kubeadm upgrade 命令
	5. kubeadm token 管理 kubeadm join 使用的令牌
	6. kubeadm reset 还原 kubeadm init 或者 kubeadm join 对主机所做的任何更改

添加文件kubeadm.yaml
apiVersion: kubeadm.k8s.io/v1beta2
kind: ClusterConfiguration
controllerManager:
  extraArgs:
    horizontal-pod-autoscaler-use-rest-clients: "true"
    horizontal-pod-autoscaler-sync-period: "10s"
    node-monitor-grace-period: "10s"
apiServer:
  extraArgs:
    runtime-config: "api/all=true"
kubernetesVersion: v1.22.2
cgroupDriver: systemd

#### 拉取镜像
首先使用下面的命令获取需要的docker镜像名称：
	
	kubeadm config images list
	[root@localhost ~]# kubeadm config images list
	k8s.gcr.io/kube-apiserver:v1.22.2
	k8s.gcr.io/kube-controller-manager:v1.22.2
	k8s.gcr.io/kube-scheduler:v1.22.2
	k8s.gcr.io/kube-proxy:v1.22.2
	k8s.gcr.io/pause:3.5
	k8s.gcr.io/etcd:3.5.0-0
	k8s.gcr.io/coredns/coredns:v1.8.4

编写脚本：vi pull_k8s_images.sh

	set -o errexit
	set -o nounset
	set -o pipefail
	
	##这里定义版本，按照上面得到的列表自己改一下版本号
	
	KUBE_VERSION=v1.22.2
	KUBE_PAUSE_VERSION=3.5
	ETCD_VERSION=3.5.0-0
	DNS_VERSION=v1.8.4
	
	##这是原始仓库名，最后需要改名成这个
	GCR_URL=k8s.gcr.io
	
	##这里就是写你要使用的仓库
	DOCKERHUB_URL=gotok8s
	
	##这里是镜像列表，新版本要把coredns改成coredns/coredns
	images=(
	kube-proxy:${KUBE_VERSION}
	kube-scheduler:${KUBE_VERSION}
	kube-controller-manager:${KUBE_VERSION}
	kube-apiserver:${KUBE_VERSION}
	pause:${KUBE_PAUSE_VERSION}
	etcd:${ETCD_VERSION}
	coredns:${DNS_VERSION}
	)
	
	##这里是拉取和改名的循环语句
	for imageName in ${images[@]} ; do
	  docker pull $DOCKERHUB_URL/$imageName
	  docker tag $DOCKERHUB_URL/$imageName $GCR_URL/$imageName
	  docker rmi $DOCKERHUB_URL/$imageName
	done

执行 :chmod +x ./pull_k8s_images.sh && ./pull_k8s_images.sh

执行:kubeadm init  --config kubeadm.yaml
发现报错:failed to pull image k8s.gcr.io/coredns/coredns:v1.8.4

我们下载的镜像和需要的镜像名字不同,修改一下:
	
	docker tag k8s.gcr.io/coredns:v1.8.4 k8s.gcr.io/coredns/coredns:v1.8.4
在执行: kubeadm init  --config kubeadm.yaml

### 离线部署

在https://github.com/lework/kainstall-offline/releases下载安装包打包
下载脚本:https://github.com/lework/kainstall
wget https://cdn.jsdelivr.net/gh/lework/kainstall@master/kainstall-centos.sh

安装集群:
bash kainstall-centos.sh init \
  --master 192.168.77.130,192.168.77.131,192.168.77.132 \
  --worker 192.168.77.133,192.168.77.134 \
  --user root \
  --password 123456 \
  --version 1.20.6 \
  --upgrade-kernel \
  --10years \
  --offline-file 1.20.6_centos7.tgz